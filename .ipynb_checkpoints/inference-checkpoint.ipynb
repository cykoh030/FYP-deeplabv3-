{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "# vipshome = 'E:/chengyong/vips-dev-8.10/bin'\n",
    "# os.environ['PATH'] = vipshome + ';' + os.environ['PATH']\n",
    "# import pyvips\n",
    "import re\n",
    "from numba import jit, cuda\n",
    "import random\n",
    "import tkinter as tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from scipy import misc\n",
    "import imageio\n",
    "%matplotlib inline \n",
    "from matplotlib import image as matimg\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "from deeplab import DeepLabV3Plus, ASPP\n",
    "from resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "from tensorflow.python.keras.utils.all_utils import multi_gpu_model\n",
    "from tensorflow.python.keras.utils.all_utils import Sequence\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "print('Tensorflow', tf.__version__)\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 800, 1600\n",
    "with open('cityscapes_dict.pkl', 'rb') as f:\n",
    "    id_to_color = pickle.load(f)['color_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_to_color[8] = (128, 64,128) # sidewalk to road\n",
    "id_to_color[10] = (128, 64,128) # rail track to road\n",
    "id_to_color[6] = (128, 64,128) # ground to road\n",
    "id_to_color[12] = (70, 70, 70) # wall to building\n",
    "id_to_color[13] = (70, 70, 70) # fence to building\n",
    "id_to_color[17] = (70, 70, 70) # guard rail to building\n",
    "id_to_color[18] = (70, 70, 70) # pole to building\n",
    "id_to_color[19] = (70, 70, 70) # polegroup to building\n",
    "id_to_color[20] = (70, 70, 70) # traffic light to building\n",
    "id_to_color[14] = (70, 70, 70) # traffic sign to building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_to_id = {(0, 0, 0): 0,\n",
    " (111, 74, 0): 1,\n",
    " (128, 64, 128): 2,\n",
    " (250, 170, 160): 3,\n",
    " (230, 150, 140): 4,\n",
    " (70, 70, 70): 5,\n",
    " (150, 100, 100): 6,\n",
    " (150, 120, 90): 7,\n",
    " (153, 153, 153): 8,\n",
    " (250, 170, 30): 9,\n",
    " (220, 220, 0): 10,\n",
    " (107, 142, 35): 11,\n",
    " (152, 251, 152): 12,\n",
    " (70, 130, 180): 13,\n",
    " (220, 20, 60): 14,\n",
    " (255, 0, 0): 15,\n",
    " (0, 0, 142): 16,\n",
    " (0, 0, 70): 17,\n",
    " (0, 60, 100): 18,\n",
    " (0, 0, 90): 19,\n",
    " (0, 0, 110): 20,\n",
    " (0, 80, 100): 21,\n",
    " (0, 0, 230): 22,\n",
    " (119, 11, 32): 23,\n",
    " (0, 0, 142): 24}\n",
    "\n",
    "# color_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Building DeepLabv3Plus Network ***\n",
      "*** Output_Shape => (None, 800, 1600, 34) ***\n"
     ]
    }
   ],
   "source": [
    "model = DeepLabV3Plus(h, w, 34)\n",
    "model.load_weights('last_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pipeline(image, video=True, return_seg=False, fname='', folder='', downsampling=1):\n",
    "#     global b\n",
    "#     alpha = 0.5\n",
    "#     dims = image.shape\n",
    "#     image = cv2.resize(image, (w, h))\n",
    "#     x = image.copy()\n",
    "#     z = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "    \n",
    "#     z = np.squeeze(z)\n",
    "#     y = np.argmax(z, axis=2)\n",
    "    \n",
    "#     img_color = image.copy()   \n",
    "#     for i in np.unique(y):\n",
    "#         if i in id_to_color:\n",
    "#             img_color[y==i] = id_to_color[i]\n",
    "#     disp = img_color.copy()\n",
    "#     if video:\n",
    "#         cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)        \n",
    "#         return img_color\n",
    "#     if return_seg:\n",
    "#         return img_color/255.\n",
    "#     else:\n",
    "#         cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)      \n",
    "# #         plt.figure(figsize=(20, 10))\n",
    "# #         out = np.concatenate([image/255, img_color/255, disp/255], axis=1)\n",
    "        \n",
    "# #         plt.imshow(img_color/255.0)\n",
    "# #         plt.imshow(out)\n",
    "#         if not os.path.exists('Output'):\n",
    "#             os.makedirs('Output')\n",
    "#         return cv2.imwrite(f'Output/{folder}/{fname}',  cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationPipeline():\n",
    "    def __init__(self, video=True, return_seg=False, folder='', fname='{}.jpg', downsample=1, interp='linear', output_dir=''):\n",
    "        self.video = video\n",
    "        self.return_seg = return_seg\n",
    "        self.folder = folder\n",
    "        self.downsample = downsample\n",
    "        self.interp = interp\n",
    "        self.prev_z = None\n",
    "        self.index = 0\n",
    "        self.fname = fname\n",
    "        self.alpha = 0.5\n",
    "        self.miou_ls = []\n",
    "        self.output_dir=output_dir\n",
    "        \n",
    "        if interp != 'linear' and interp != 'cosine':\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def pipe(self, image, overlays=None):\n",
    "        alpha = 0.5\n",
    "        dims = image.shape\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        x = image.copy()\n",
    "        curr_z = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "        curr_z = np.squeeze(curr_z)\n",
    "        \n",
    "        for i in range(self.downsample):\n",
    "            if self.index == 0 and i < self.downsample - 1: \n",
    "                continue\n",
    "            \n",
    "            if self.downsample > 1 and i < self.downsample - 1:\n",
    "                curr_weight = (i+1)/self.downsample\n",
    "                prev_weight = 1. - curr_weight\n",
    "                if self.interp == 'linear':\n",
    "                    interp_z = prev_weight * self.prev_z + curr_weight * curr_z\n",
    "                if self.interp == 'cosine':\n",
    "                    interp_z = 0.5 * ((1 - math.cos(curr_weight*180)) * (curr_z-self.prev_z))\n",
    "\n",
    "            else:\n",
    "                interp_z = curr_z\n",
    "            \n",
    "            y = np.argmax(interp_z, axis=2)\n",
    "\n",
    "            img_color = image.copy()\n",
    "            for j in np.unique(y):\n",
    "                if j in id_to_color:\n",
    "                    img_color[y==j] = id_to_color[j]\n",
    "\n",
    "            if self.video:\n",
    "                cv2.addWeighted(image, self.alpha, img_color, 1-self.alpha, 0, img_color)        \n",
    "                out = img_color\n",
    "            else:\n",
    "                if self.return_seg:\n",
    "                    # out = img_color/255.\n",
    "                    if not os.path.exists(self.output_dir):\n",
    "                        os.makedirs(self.output_dir)\n",
    "\n",
    "                    thefilename = self.fname.format(self.index)\n",
    "                    out = img_color\n",
    "                    cv2.imwrite(self.output_dir + f'/{self.folder}/{thefilename}',  cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR))\n",
    "                    \n",
    "                else:\n",
    "                    if overlays is not None:\n",
    "                        if len(overlays) > 1:\n",
    "                            overlay = overlays[i]  \n",
    "                        else:\n",
    "                            overlay = overlays[0]\n",
    "                        overlay = cv2.resize(overlay, (w, h))\n",
    "                    else:\n",
    "                        overlay = image\n",
    "\n",
    "                    cv2.addWeighted(overlay, self.alpha, img_color, 1-self.alpha, 0, img_color)\n",
    "\n",
    "                    if not os.path.exists(self.output_dir):\n",
    "                        os.makedirs(self.output_dir)\n",
    "                        \n",
    "                    thefilename = self.fname.format(self.index)\n",
    "                    out = cv2.imwrite(self.output_dir + f'/{self.folder}/{thefilename}',  cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR))   \n",
    "                    \n",
    "            self.index += 1\n",
    "    \n",
    "        self.prev_z = curr_z\n",
    "        \n",
    "        \n",
    "\n",
    "    def iouTest(self, image):\n",
    "        dims = image.shape\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        x = image.copy()\n",
    "        curr_z = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "        curr_z = np.squeeze(curr_z)\n",
    "\n",
    "        curr_z_array = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "        curr_z_array = np.squeeze(curr_z_array)\n",
    "        \n",
    "        for i in range(self.downsample):\n",
    "            if self.index == 0 and i < self.downsample - 1: \n",
    "                continue\n",
    "            \n",
    "            if self.downsample > 1 and i < self.downsample - 1:\n",
    "                curr_weight = (i+1)/self.downsample\n",
    "                prev_weight = 1. - curr_weight\n",
    "\n",
    "                interp_z = prev_weight * self.prev_z + curr_weight * curr_z\n",
    "                curr_z_array = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "                curr_z_array = np.squeeze(curr_z_array)\n",
    "            else:\n",
    "                interp_z = curr_z\n",
    "            \n",
    "            y = np.argmax(interp_z, axis=2)\n",
    "            y2 = np.argmax(curr_z_array, axis=2)\n",
    "\n",
    "            ## mIOU\n",
    "            num_classes=34\n",
    "            IOU_keras = MeanIoU(num_classes=num_classes)\n",
    "            IOU_keras.update_state(y, y2)\n",
    "            iou = IOU_keras.result().numpy()\n",
    "            if iou != 1:\n",
    "                self.miou_ls.append(iou)\n",
    "\n",
    "            self.index += 1\n",
    "    \n",
    "        self.prev_z = curr_z\n",
    "        if self.miou_ls:\n",
    "            miou = sum(self.miou_ls) / len(self.miou_ls)\n",
    "            # print(\"Mean IoU =\", miou)\n",
    "            return miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path is: E:/chengyong/gitproject/DeepLabv3plus_tf2-4-1/imgs/test_0001.jpg\n",
      "Working diretory is: E:\\chengyong\\gitproject\\DeepLabv3plus_tf2-4-1\\imgs\n",
      "26 frames found\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)\n",
    "\n",
    "file_path = askopenfilename(parent=root,title='Select .txt') \n",
    "os.chdir(os.path.dirname(os.path.realpath(file_path)))\n",
    "directory_path = os.getcwd()\n",
    "image_dir = sorted(glob(directory_path + \"/*.jpg\",recursive=False))\n",
    "print(\"File path is: \" + file_path)\n",
    "print(\"Working diretory is: \" + directory_path)\n",
    "print(f'{len(image_dir)} frames found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingVIPS(f,w,h):\n",
    "#     image = pyvips.Image.new_from_file(f, access=\"sequential\")\n",
    "#     image = image.colourspace(\"srgb\")\n",
    "#     mem_img = image.write_to_memory() \n",
    "#     imgnp=np.frombuffer(mem_img, dtype=np.uint8).reshape(image.height, image.width, 3)  \n",
    "#     return imgnp \n",
    "\n",
    "    img = cv2.imread(f)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgnp = cv2.resize(img, (w,h))\n",
    "    return imgnp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_fps = 30\n",
    "segmentation_fps = 30\n",
    "assert video_fps % segmentation_fps == 0\n",
    "downsample = video_fps//segmentation_fps\n",
    "downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear interpolation procedure:<br/> \n",
    "    pipeline calls class > run init<br/>\n",
    "    first iteration: i = 0, > pipe fn call > idx=0 > continue > self.prev_z = curr_z<br/>\n",
    "    2&3 iteration: overlays.append<br/>\n",
    "    4th iteration:  i = 3, > pipe fn call > idx=0 > continue ><br/>\n",
    "                    idx=1 > interp_z = weighted_z > y = pixelclass > map to color > len(overlays)=3, overlay=overlays[1] > output img > idx+1 ><br/>\n",
    "                    idx=2 > interp_z = curr_z > y = pixelclass > map to color > len(overlays)=3, overlay=overlays[2] > output img > return out<br/><br/>\n",
    "\n",
    "downsample by 2: Mean IoU - 0.6650284518454584 (100 frames), 0.6868347733202397 (900 frames)<br/>\n",
    "downsample by 3: Mean IoU - 0.6372878962617363 (100 frames), 0.6633182627375996 (900 frames)<br/>\n",
    "downsample by 5: Mean IoU - 0.6082032569932402 (100 frames), 0.6311255016647166 (900 ftames)<br/>\n",
    "downsample by 6: Mean IoU - 0.5928199723863794 (100 frames), 0.6220667065127788 (900 frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = SegmentationPipeline(\n",
    "    video=False, \n",
    "    return_seg=False, \n",
    "    folder='', \n",
    "    fname='waterfeature_{}.jpg', \n",
    "    downsample=downsample, \n",
    "    interp='linear',\n",
    "    output_dir='segonly'\n",
    ")\n",
    "\n",
    "overlays = []\n",
    "miou_ls = []\n",
    "for i in tqdm(range(len(image_dir)), desc = \"Prediction Progress\"):\n",
    "    try:\n",
    "        # test = load_img(image_dir[i])\n",
    "        # test = img_to_array(test)\n",
    "        test = usingVIPS(image_dir[i],w,h)\n",
    "        \n",
    "        if i % downsample == 0:\n",
    "            iou = pipeline.iouTest(\n",
    "                image=test,\n",
    "            )\n",
    "            if iou != None:\n",
    "                miou_ls.append(iou)\n",
    "        if segmap == False:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "miou = sum(miou_ls) / len(miou_ls)\n",
    "print(\"Final mIOU: \", miou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Progress: 100%|█████████████████████████████████████████████████████████████| 26/26 [00:19<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = SegmentationPipeline(\n",
    "    video=False, \n",
    "    return_seg=True, \n",
    "    folder='', \n",
    "    fname='waterfeature_{}.jpg', \n",
    "    downsample=downsample, \n",
    "    interp='linear',\n",
    "    output_dir='segonly'\n",
    ")\n",
    "\n",
    "overlays = []\n",
    "for i in tqdm(range(len(image_dir)), desc = \"Prediction Progress\"):\n",
    "    try:\n",
    "        # test = load_img(image_dir[i])\n",
    "        # test = img_to_array(test)\n",
    "        test = usingVIPS(image_dir[i],w,h)\n",
    "        \n",
    "        overlays.append(test)\n",
    "        \n",
    "        if i % downsample == 0:\n",
    "            segmap = pipeline.pipe(\n",
    "                image=test,\n",
    "                overlays=overlays\n",
    "            )\n",
    "            overlays = []\n",
    "        if segmap == False:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with VIPS: Prediction Progress: 100%|██████████| 1050/1050 [12:28<00:00,  1.40it/s]<br/>\n",
    "with cv2: Prediction Progress: 100%|██████████| 1050/1050 [13:26<00:00,  1.30it/s]<br/><br/>\n",
    "\n",
    "image.resize: 45.8 ms ± 2.81 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)<br/>\n",
    "argmax: 3.51 ms ± 284 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)<br/>\n",
    "cv2.addweighted: 42.5 ms ± 3.09 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)<br/>\n",
    "cv2.imwrite: 3.55 ms ± 146 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalMergeIntoVideo(directory_path):\n",
    "    dirFiles = []\n",
    "    for filename in glob(directory_path + \"/*.jpg\",recursive=False):\n",
    "        dirFiles.append(filename)\n",
    "\n",
    "    dirFiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "    img_array = []\n",
    "    for filename in tqdm(dirFiles, desc=\"Reading Progress\"):\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "\n",
    "    video = cv2.VideoWriter(directory_path + '/30fps2.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 7.5, size)\n",
    "\n",
    "    for i in tqdm(range(len(img_array)), desc = \"Video Merging Progress\"):\n",
    "        video.write(img_array[i])\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Progress: 100%|████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 35.66it/s]\n",
      "Video Merging Progress: 100%|██████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 67.66it/s]\n"
     ]
    }
   ],
   "source": [
    "numericalMergeIntoVideo(directory_path + \"/segonly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_path = \"E:/chengyong/semantic/videos_cropped_black/test__r0010/car_python_seg/30fps/waterfeature20.jpg\"\n",
    "rawx_path = \"E:/chengyong/semantic/videos_cropped_black/test__r0010/car/30fps_image/test_0001.jpg\"\n",
    "interp_path = \"E:/chengyong/gitproject/DeepLabv3plus_tf2-4-1/imgs/Output/waterfeature_0.jpg\"\n",
    "truth_path = \"E:/chengyong/semantic/videos_cropped_black/test__r0010/car/30fps_image/Output/waterfeature_0.jpg\"\n",
    "\n",
    "rawx = usingVIPS(rawx_path)\n",
    "interp = usingVIPS(interp_path)\n",
    "rawx = cv2.resize(rawx, (w, h))\n",
    "truth = usingVIPS(truth_path)\n",
    "\n",
    "# num_classes=34\n",
    "# IOU_keras = MeanIoU(num_classes=num_classes)\n",
    "# IOU_keras.update_state(interp, truth)\n",
    "# print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modeltest = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', metrics=['accuracy',tf.keras.metrics.MeanIoU(34, name='mIoU')])\n",
    "# model.compile(optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testz = modeltest.predict(preprocess_input(np.expand_dims(rawx,axis=0)))\n",
    "testz = np.squeeze(testz)\n",
    "testy = np.argmax(testz, axis=2)\n",
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.expand_dims(truth,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(np.expand_dims(interp,axis=0),np.expand_dims(truth,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=34\n",
    "IOU_keras = MeanIoU(num_classes=num_classes)\n",
    "IOU_keras.update_state(a, testy)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstest = [1,2,3,4,5,6,7,8,9,10]\n",
    "lstest = sum(lstest) / len(lstest)\n",
    "lstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2mask(img):\n",
    "\n",
    "    assert len(img.shape) == 3\n",
    "    height, width, ch = img.shape\n",
    "    assert ch == 3\n",
    "\n",
    "    W = np.power(256, [[0],[1],[2]])\n",
    "\n",
    "    img_id = img.dot(W).squeeze(-1) \n",
    "    values = np.unique(img_id)\n",
    "\n",
    "    mask = np.zeros(img_id.shape)\n",
    "\n",
    "    for i, c in enumerate(values):\n",
    "        try:\n",
    "            mask[img_id==c] = color_to_id[tuple(img[img_id==c][0])] \n",
    "        except:\n",
    "            pass\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rgb2mask(interp)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "bld = truth\n",
    "seg = cv2.addWeighted(bld,1/alpha,rawx,1-1/alpha, 0)\n",
    "plt.imshow(bld, interpolation='nearest')\n",
    "plt.show()\n",
    "bld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = usingVIPS(file_path)\n",
    "raw = cv2.resize(raw, (w,h))\n",
    "seg = usingVIPS(directory_path + \"/Output/waterfeature_0.jpg\")\n",
    "bld = cv2.addWeighted(seg,alpha,raw,1-alpha, 0)\n",
    "plt.imshow(bld, interpolation='nearest')\n",
    "plt.show()\n",
    "seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9d631ec8b8d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Iterating through the json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'emp_details'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import json\n",
    "  \n",
    "f = open ('E:/export-2021-05-27T03 44 40.909Z.json', \"r\")\n",
    "decoded = json.loads('E:/export-2021-05-27T03 44 40.909Z.json')\n",
    "  \n",
    "# Reading from file\n",
    "data = json.loads(f.read())\n",
    "  \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in data['emp_details']:\n",
    "    print(i)\n",
    "  \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 'ckp6cpd2h1q2u266bkvxl61n7',\n",
       "  'DataRow ID': 'ckp6c2i532of50yw3b7r95duh',\n",
       "  'Labeled Data': 'https://storage.labelbox.com/ckp69pibc2hi50y9z4hnu5g52%2Fd55a94c0-c0bd-d3db-aa7c-564beede9fbf-test_0021.jpg?Expires=1623296680925&KeyName=labelbox-assets-key-3&Signature=grSNxVor20W9Cpu0g17h63aBQRg',\n",
       "  'Label': {'objects': [{'featureId': 'ckp6cbovs0000266bh3tp7gzx',\n",
       "     'schemaId': 'ckp6cay0m2qua0y7dh1586y7e',\n",
       "     'title': 'human',\n",
       "     'value': 'human',\n",
       "     'color': '#FF34FF',\n",
       "     'instanceURI': 'https://api.labelbox.com/masks/feature/ckp6cbovs0000266bh3tp7gzx?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3A2OXBpYnAyaGk2MHk5ejZkZG9lcGYxIiwib3JnYW5pemF0aW9uSWQiOiJja3A2OXBpYmMyaGk1MHk5ejRobnU1ZzUyIiwiaWF0IjoxNjIyMDg3MDgwLCJleHAiOjE2MjQ2NzkwODB9.f_mJ-_E3uCMrLZurfnvBzi_CowyKjw0zNrJWuK2draA'},\n",
       "    {'featureId': 'ckp6ci63k0ge1266bsa3oi48u',\n",
       "     'schemaId': 'ckp6cay0n2que0y7dc40a2i7x',\n",
       "     'title': 'sky',\n",
       "     'value': 'sky',\n",
       "     'color': '#008941',\n",
       "     'instanceURI': 'https://api.labelbox.com/masks/feature/ckp6ci63k0ge1266bsa3oi48u?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3A2OXBpYnAyaGk2MHk5ejZkZG9lcGYxIiwib3JnYW5pemF0aW9uSWQiOiJja3A2OXBpYmMyaGk1MHk5ejRobnU1ZzUyIiwiaWF0IjoxNjIyMDg3MDgwLCJleHAiOjE2MjQ2NzkwODB9.f_mJ-_E3uCMrLZurfnvBzi_CowyKjw0zNrJWuK2draA'},\n",
       "    {'featureId': 'ckp6cip2j0maa266bzp3cr45p',\n",
       "     'schemaId': 'ckp6cay0m2qu80y7d1h80fqfs',\n",
       "     'title': 'construction',\n",
       "     'value': 'construction',\n",
       "     'color': '#1CE6FF',\n",
       "     'instanceURI': 'https://api.labelbox.com/masks/feature/ckp6cip2j0maa266bzp3cr45p?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3A2OXBpYnAyaGk2MHk5ejZkZG9lcGYxIiwib3JnYW5pemF0aW9uSWQiOiJja3A2OXBpYmMyaGk1MHk5ejRobnU1ZzUyIiwiaWF0IjoxNjIyMDg3MDgwLCJleHAiOjE2MjQ2NzkwODB9.f_mJ-_E3uCMrLZurfnvBzi_CowyKjw0zNrJWuK2draA'}],\n",
       "   'classifications': []},\n",
       "  'Created By': 'jeffkcy32@gmail.com',\n",
       "  'Project Name': 'test',\n",
       "  'Created At': '2021-05-27T03:42:56.000Z',\n",
       "  'Updated At': '2021-05-27T03:42:58.000Z',\n",
       "  'Seconds to Label': 492.648,\n",
       "  'External ID': 'test_0021.jpg',\n",
       "  'Agreement': -1,\n",
       "  'Benchmark Agreement': -1,\n",
       "  'Benchmark ID': None,\n",
       "  'Dataset Name': '100frames',\n",
       "  'Reviews': [],\n",
       "  'View Label': 'https://editor.labelbox.com?project=ckp6c8z4t0a8n0776mll91i2r&label=ckp6cpd2h1q2u266bkvxl61n7',\n",
       "  'Has Open Issues': 0}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open ('E:/export-2021-05-27T03 44 40.909Z.json', \"r\")\n",
    "decoded = json.loads(f.read())\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
