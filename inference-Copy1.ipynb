{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from numba import jit, cuda\n",
    "import random\n",
    "import tkinter as tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from scipy import misc\n",
    "import imageio\n",
    "%matplotlib inline \n",
    "from matplotlib import image as matimg\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "from deeplab import DeepLabV3Plus, ASPP\n",
    "from resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "from tensorflow.python.keras.utils.all_utils import multi_gpu_model\n",
    "from tensorflow.python.keras.utils.all_utils import Sequence\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "print('Tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 800, 1600\n",
    "with open('cityscapes_dict.pkl', 'rb') as f:\n",
    "    id_to_color = pickle.load(f)['color_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_to_color[8] = (128, 64,128) # sidewalk to road\n",
    "id_to_color[6] = (128, 64,128) # ground to road\n",
    "id_to_color[12] = (70, 70, 70) # wall to building\n",
    "id_to_color[13] = (70, 70, 70) # fence to building\n",
    "id_to_color[14] = (70, 70, 70) # guard rail to building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Building DeepLabv3Plus Network ***\n",
      "*** Output_Shape => (None, 800, 1600, 34) ***\n"
     ]
    }
   ],
   "source": [
    "model = DeepLabV3Plus(h, w, 34)\n",
    "model.load_weights('last_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pipeline(image, video=True, return_seg=False, fname='', folder='', downsampling=1):\n",
    "#     global b\n",
    "#     alpha = 0.5\n",
    "#     dims = image.shape\n",
    "#     image = cv2.resize(image, (w, h))\n",
    "#     x = image.copy()\n",
    "#     z = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "    \n",
    "#     z = np.squeeze(z)\n",
    "#     y = np.argmax(z, axis=2)\n",
    "    \n",
    "#     img_color = image.copy()   \n",
    "#     for i in np.unique(y):\n",
    "#         if i in id_to_color:\n",
    "#             img_color[y==i] = id_to_color[i]\n",
    "#     disp = img_color.copy()\n",
    "#     if video:\n",
    "#         cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)        \n",
    "#         return img_color\n",
    "#     if return_seg:\n",
    "#         return img_color/255.\n",
    "#     else:\n",
    "#         cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)      \n",
    "# #         plt.figure(figsize=(20, 10))\n",
    "# #         out = np.concatenate([image/255, img_color/255, disp/255], axis=1)\n",
    "        \n",
    "# #         plt.imshow(img_color/255.0)\n",
    "# #         plt.imshow(out)\n",
    "#         if not os.path.exists('Output'):\n",
    "#             os.makedirs('Output')\n",
    "#         return cv2.imwrite(f'Output/{folder}/{fname}',  cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationPipeline():\n",
    "    def __init__(self, video=True, return_seg=False, folder='', fname='{}.jpg', downsample=1, interp='linear'):\n",
    "        self.video = video\n",
    "        self.return_seg = return_seg\n",
    "        self.folder = folder\n",
    "        self.downsample = downsample\n",
    "        self.prev_z = None\n",
    "        self.index = 0\n",
    "        self.fname = fname\n",
    "        \n",
    "        if interp != 'linear':\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def pipe(self, image, overlays=None):\n",
    "        alpha = 0.5\n",
    "        dims = image.shape\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        x = image.copy()\n",
    "        curr_z = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n",
    "        curr_z = np.squeeze(curr_z)\n",
    "        \n",
    "        for i in range(self.downsample):\n",
    "#             print(self.index)\n",
    "            if self.index == 0 and i < self.downsample - 1:\n",
    "                continue\n",
    "            \n",
    "            if self.downsample > 1 and i < self.downsample - 1:\n",
    "                curr_weight = (i+1)/self.downsample\n",
    "                prev_weight = 1. - curr_weight\n",
    "\n",
    "                interp_z = prev_weight * self.prev_z + curr_weight * curr_z\n",
    "            else:\n",
    "                interp_z = curr_z\n",
    "            \n",
    "            y = np.argmax(interp_z, axis=2)\n",
    "            \n",
    "            img_color = image.copy()   \n",
    "            for j in np.unique(y):\n",
    "                if j in id_to_color:\n",
    "                    img_color[y==j] = id_to_color[j]\n",
    "\n",
    "            if self.video:\n",
    "                cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)        \n",
    "                out = img_color\n",
    "            else:\n",
    "                if self.return_seg:\n",
    "                    out = img_color/255.\n",
    "                else:\n",
    "                    if overlays is not None:\n",
    "                        if len(overlays) > 1:\n",
    "                            overlay = overlays[i]  \n",
    "                        else:\n",
    "                            overlay = overlays[0]\n",
    "                        overlay = cv2.resize(overlay, (w, h))\n",
    "                    else:\n",
    "                        overlay = image\n",
    "\n",
    "                    cv2.addWeighted(overlay, alpha, img_color, 1-alpha, 0, img_color)\n",
    "\n",
    "                    if not os.path.exists('Output'):\n",
    "                        os.makedirs('Output')\n",
    "                        \n",
    "                    thefilename = self.fname.format(self.index)\n",
    "#                     print(thefilename)\n",
    "                    out = cv2.imwrite(f'Output/{self.folder}/{thefilename}',  cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR))    \n",
    "                    \n",
    "            self.index += 1\n",
    "    \n",
    "        self.prev_z = curr_z\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path is: E:/chengyong/gitproject/DeepLabv3plus_tf2-4-1/imgs/test_0001.jpg\n",
      "Working diretory is: E:\\chengyong\\gitproject\\DeepLabv3plus_tf2-4-1\\imgs\n",
      "100 frames found\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)\n",
    "\n",
    "file_path = askopenfilename(parent=root,title='Select .txt') \n",
    "os.chdir(os.path.dirname(os.path.realpath(file_path)))\n",
    "directory_path = os.getcwd()\n",
    "image_dir = sorted(glob(directory_path + \"/*.jpg\",recursive=False))\n",
    "print(\"File path is: \" + file_path)\n",
    "print(\"Working diretory is: \" + directory_path)\n",
    "print(f'{len(image_dir)} frames found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = sorted(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fps = 30\n",
    "segmentation_fps = 10\n",
    "assert video_fps % segmentation_fps == 0\n",
    "downsample = video_fps//segmentation_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction Progress: 100%|███████████████████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = SegmentationPipeline(\n",
    "    video=False, \n",
    "    return_seg=False, \n",
    "    folder='', \n",
    "    fname='waterfeature_{}.jpg', \n",
    "    downsample=downsample, \n",
    "    interp='linear'\n",
    ")\n",
    "\n",
    "overlays = []\n",
    "for i in tqdm(range(len(image_dir)), desc = \"Prediction Progress\"):\n",
    "    try:\n",
    "        test = load_img(image_dir[i])\n",
    "        test = img_to_array(test)\n",
    "        \n",
    "        overlays.append(test)\n",
    "        \n",
    "        if i % downsample == 0:\n",
    "            segmap = pipeline.pipe(\n",
    "                test,\n",
    "                overlays\n",
    "            )\n",
    "            overlays = []\n",
    "        if segmap == False:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalMergeIntoVideo(directory_path):\n",
    "    dirFiles = []\n",
    "    for filename in glob(directory_path + \"/*.jpg\",recursive=False):\n",
    "        dirFiles.append(filename)\n",
    "\n",
    "    dirFiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "    img_array = []\n",
    "    for filename in tqdm(dirFiles, desc=\"Reading Progress\"):\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "\n",
    "    video = cv2.VideoWriter(directory_path + '/30fps.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "\n",
    "    for i in tqdm(range(len(img_array)), desc = \"Video Merging Progress\"):\n",
    "        video.write(img_array[i])\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Progress: 100%|██████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 48.36it/s]\n",
      "Video Merging Progress: 100%|███████████████████████████████████████████████████████| 100/100 [00:00<00:00, 109.12it/s]\n"
     ]
    }
   ],
   "source": [
    "numericalMergeIntoVideo(directory_path + \"/Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
